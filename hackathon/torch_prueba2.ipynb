{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import cat, no_grad, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    Dropout2d,\n",
    "    NLLLoss,\n",
    "    MaxPool2d,\n",
    "    Flatten,\n",
    "    Sequential,\n",
    "    ReLU,\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from torchvision.io import read_image, image\n",
    "import os\n",
    "from torchvision.utils import make_grid\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from PIL import Image as imagePIL\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargando las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000002337CBFEC80>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000002337CBFF460>\n"
     ]
    }
   ],
   "source": [
    "# input_images_path = \"C:/Users/usuario/Documents/Yessi/EscuelaCuanticaEspañol/escuela-de-computacion-cuantica-2023/hackathon/bancos/\"\n",
    "# files_names_COVID = os.listdir(input_images_path+\"COVID\")\n",
    "# files_names_SANOS = os.listdir(input_images_path+\"SANOS\")\n",
    "# print(files_names_COVID)\n",
    "# print(files_names_SANOS)\n",
    "\n",
    "# train = []\n",
    "# etiquetas = []\n",
    "\n",
    "batch_size = 1\n",
    "transformar = transforms.Compose([\n",
    "    transforms.Resize((28,28)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "# for enf in files_names_COVID:\n",
    "#     imagenEG = transformar(imagePIL.open('bancos/COVID/'+enf).convert('L'))\n",
    "#     # print(type(imagenEG),imagenEG)\n",
    "#     train.append(imagenEG)\n",
    "# #     etiquetas.append(1)\n",
    "# # for enf in files_names_SANOS:\n",
    "# #     train.append(transformar(imagePIL.open('bancos/SANOS/'+enf).convert('L')))\n",
    "# #     etiquetas.append(0)\n",
    "# print(type((train)),(train))\n",
    "\n",
    "train = datasets.ImageFolder('C:/Users/usuario/Documents/Yessi/EscuelaCuanticaEspañol/escuela-de-computacion-cuantica-2023/hackathon/bancos/train',transform=transformar)\n",
    "test = datasets.ImageFolder('C:/Users/usuario/Documents/Yessi/EscuelaCuanticaEspañol/escuela-de-computacion-cuantica-2023/hackathon/bancos/test',transform=transformar)\n",
    "\n",
    "# print(type(enfermos.data[0][0]),enfermos.data[0][0])\n",
    "# print(\"Enfermos:\",len(files_names_COVID), \"Sanos: \",len(files_names_SANOS),\" Total: \",len(train))\n",
    "\n",
    "\n",
    "\n",
    "# enfermosTensor = []\n",
    "# # # # etiquetasTensor = s(img)\n",
    "#     # enfermosTensor.append(transformar(img))\n",
    "# # enfermosTensor = transformar(np.ndarray(train))\n",
    "# # train = torch.Tensor(train).type(torch.Tensor)\n",
    "# # etiquetasTensor = torch.Tensor(etiquetas).type(torch.LongTensor)\n",
    "\n",
    "# # torch.from_numpy(data)\n",
    "# print(type(train),train)\n",
    "train_data = DataLoader(train, batch_size=1, shuffle=True)\n",
    "test_data = DataLoader(test, batch_size=1, shuffle=True)\n",
    "print(train_data)\n",
    "print(test_data)\n",
    "\n",
    "# print(\"Enfermos:\",len(enfermosTensor), \"Etiquetas: \",len(etiquetasTensor))\n",
    "# # print(etiquetasTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muestra de Imagenes del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples_show = 2\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "for ind, (i,c) in enumerate(train_data):\n",
    "    axes[ind].imshow(i[0,0], cmap=\"gray\")\n",
    "    axes[ind].set_xticks([])\n",
    "    axes[ind].set_yticks([])\n",
    "    axes[ind].set_title(\"Labeled: {}\".format(i.shape))\n",
    "    n_samples_show -= 1\n",
    "    if n_samples_show == 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Hibrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qnn():\n",
    "    feature_map = ZZFeatureMap(2)\n",
    "    ansatz = RealAmplitudes(2, reps=1)\n",
    "    qc = QuantumCircuit(2)\n",
    "    qc.compose(feature_map, inplace=True)\n",
    "    qc.compose(ansatz, inplace=True)\n",
    "\n",
    "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        input_gradients=True,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "\n",
    "qnn4 = create_qnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):\n",
    "    def __init__(self, qnn):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(1, 2, kernel_size=5)\n",
    "        self.conv2 = Conv2d(2, 16, kernel_size=5)\n",
    "        self.dropout = Dropout2d()\n",
    "        self.fc1 = Linear(256, 64)#238144, 64)\n",
    "        self.fc2 = Linear(64, 2)  # 2-dimensional input to QNN\n",
    "        self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        # uniformly at random from interval [-1,1].\n",
    "        self.fc3 = Linear(1, 1)  # 1-dimensional output from QNN\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.qnn(x)  # apply QNN\n",
    "        x = self.fc3(x)\n",
    "        return cat((x, 1 - x), -1)\n",
    "\n",
    "\n",
    "model4 = Net(qnn4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manda llamar el modelo para entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training [10%]\tLoss: -1.0650\n",
      "Training [20%]\tLoss: -1.8057\n",
      "Training [30%]\tLoss: -2.5112\n",
      "Training [40%]\tLoss: -3.1501\n",
      "Training [50%]\tLoss: -3.7730\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model4.parameters(), lr=0.001)\n",
    "loss_func = NLLLoss()\n",
    "\n",
    "# Start training\n",
    "epochs = 10  # Set number of epochs\n",
    "loss_list = []  # Store loss history\n",
    "model4.train()  # Set model to training mode\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data,label) in enumerate(train_data):\n",
    "        optimizer.zero_grad(set_to_none=True)  # Initialize gradient\n",
    "        output = model4(data)  # Forward pass\n",
    "        loss = loss_func(output, label)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize weights\n",
    "        total_loss.append(loss.item())  # Store loss\n",
    "    loss_list.append(sum(total_loss) / len(total_loss))\n",
    "    print(\"Training [{:.0f}%]\\tLoss: {:.4f}\".format(100.0 * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title(\"Hybrid NN Training Convergence\")\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"Neg. Log Likelihood Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title(\"Hybrid NN Training Convergence\")\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"Neg. Log Likelihood Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model4.state_dict(), \"model4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnn5 = create_qnn()\n",
    "model5 = Net(qnn5)\n",
    "model5.load_state_dict(torch.load(\"model4.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.eval()  # set model to evaluation mode\n",
    "with no_grad():\n",
    "\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_data):\n",
    "        output = model5(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(test_data) / 1 * 100\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_show = 6\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "model5.eval()\n",
    "with no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_data):\n",
    "        if count == n_samples_show:\n",
    "            break\n",
    "        output = model5(data[0:1])\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        axes[count].imshow(data[0].numpy().squeeze(), cmap=\"gray\")\n",
    "\n",
    "        axes[count].set_xticks([])\n",
    "        axes[count].set_yticks([])\n",
    "        axes[count].set_title(\"Predicted {}\".format(pred.item()))\n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed(42)\n",
    "\n",
    "batch_size = 1\n",
    "n_samples = 10  # We will concentrate on the first 100 samples\n",
    "\n",
    "# Use pre-defined torchvision function to load MNIST train data\n",
    "X_train = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "# Filter out labels (originally 0-9), leaving only labels 0 and 1\n",
    "idx = np.append(\n",
    "    np.where(X_train.targets == 0)[0][:n_samples], np.where(X_train.targets == 1)[0][:n_samples]\n",
    ")\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "\n",
    "# # Define torch dataloader with filtered data\n",
    "train_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)\n",
    "print(train_loader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_show = 6\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "while n_samples_show > 0:\n",
    "    images, targets = data_iter.__next__()\n",
    "    axes[n_samples_show - 1].imshow(images[0, 0].numpy().squeeze(), cmap=\"gray\")\n",
    "    axes[n_samples_show - 1].set_xticks([])\n",
    "    axes[n_samples_show - 1].set_yticks([])\n",
    "    axes[n_samples_show - 1].set_title(\"Labeled: {}\".format(targets[0].item()))\n",
    "\n",
    "    n_samples_show -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "\n",
    "# Use pre-defined torchvision function to load MNIST test data\n",
    "X_test = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "# Filter out labels (originally 0-9), leaving only labels 0 and 1\n",
    "idx = np.append(\n",
    "    np.where(X_test.targets == 0)[0][:n_samples], np.where(X_test.targets == 1)[0][:n_samples]\n",
    ")\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "\n",
    "# Define torch dataloader with filtered data\n",
    "test_loader = DataLoader(X_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_show = 6\n",
    "\n",
    "data_iter = iter(test_loader)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "while n_samples_show > 0:\n",
    "    images, targets = data_iter.__next__()\n",
    "\n",
    "    axes[n_samples_show - 1].imshow(images[0, 0].numpy().squeeze(), cmap=\"gray\")\n",
    "    axes[n_samples_show - 1].set_xticks([])\n",
    "    axes[n_samples_show - 1].set_yticks([])\n",
    "    axes[n_samples_show - 1].set_title(\"Labeled: {}\".format(targets[0].item()))\n",
    "\n",
    "    n_samples_show -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model4.parameters(), lr=0.001)\n",
    "loss_func = NLLLoss()\n",
    "\n",
    "# Start training\n",
    "epochs = 10  # Set number of epochs\n",
    "loss_list = []  # Store loss history\n",
    "model4.train()  # Set model to training mode\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad(set_to_none=True)  # Initialize gradient\n",
    "        output = model4(data)  # Forward pass\n",
    "        print(target,\"-\",len(output),\":\",output)\n",
    "        loss = loss_func(output, target)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize weights\n",
    "        total_loss.append(loss.item())  # Store loss\n",
    "    loss_list.append(sum(total_loss) / len(total_loss))\n",
    "    print(\"Training [{:.0f}%]\\tLoss: {:.4f}\".format(100.0 * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title(\"Hybrid NN Training Convergence\")\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"Neg. Log Likelihood Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model4.state_dict(), \"model4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnn5 = create_qnn()\n",
    "model5 = Net(qnn5)\n",
    "model5.load_state_dict(torch.load(\"model4.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.eval()  # set model to evaluation mode\n",
    "with no_grad():\n",
    "\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        output = model5(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(test_loader) / batch_size * 100\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_show = 6\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "model5.eval()\n",
    "with no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if count == n_samples_show:\n",
    "            break\n",
    "        output = model5(data[0:1])\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        axes[count].imshow(data[0].numpy().squeeze(), cmap=\"gray\")\n",
    "\n",
    "        axes[count].set_xticks([])\n",
    "        axes[count].set_yticks([])\n",
    "        axes[count].set_title(\"Predicted {}\".format(pred.item()))\n",
    "\n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
